{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from epilearn.models.SpatialTemporal.STGCN import STGCN\n",
    "\n",
    "from epilearn.models.Spatial.GCN import GCN\n",
    "from epilearn.models.Spatial.SAGE import SAGE\n",
    "from epilearn.models.Spatial.GAT import GAT\n",
    "from epilearn.models.Spatial.GIN import GIN\n",
    "\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import utils, transforms\n",
    "from epilearn.utils import simulation\n",
    "from epilearn.tasks.detection import Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial settings\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(7)\n",
    "\n",
    "lookback = 1 # inputs size\n",
    "horizon = 2 # predicts size; also seen as number of classes\n",
    "\n",
    "epochs = 50 # training epochs\n",
    "batch_size = 25 # training batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load toy dataset\n",
    "dataset = UniversalDataset()\n",
    "dataset.load_toy_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Detection(prototype=GCN, dataset=None, lookback=lookback, horizon=horizon, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation = transforms.Compose({\n",
    "#                                  'features':[transforms.normalize_feat()], \n",
    "#                                  'graph': [transforms.normalize_adj()], \n",
    "#                                  'dynamic_graph': [transforms.normalize_adj()], \n",
    "#                                  'states': []\n",
    "#                                  })\n",
    "transformation = transforms.Compose({\n",
    "                                 'features':[], \n",
    "                                 'graph': [], \n",
    "                                 'dynamic_graph': [], \n",
    "                                 'states': []\n",
    "                                 })\n",
    "dataset.transforms = transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial model loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00,  7.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training loss: 0.4970368444919586\n",
      "Final Validation loss: 0.7213608622550964\n",
      "\n",
      "Predicting Progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [00:00<00:00, 1640.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.046690307557582855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "config = None\n",
    "result = task.train_model(dataset=dataset, config=config, loss='ce', epochs=5) # instead of config, we can also dircetly input some parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation Process\n",
    "from epilearn.models.SpatialTemporal.NetworkSIR import NetSIR\n",
    "\n",
    "# generate 10 samples\n",
    "num_nodes = 25\n",
    "# generate random static graph: 25 nodes\n",
    "initial_graph = simulation.get_random_graph(num_nodes=num_nodes, connect_prob=0.15)\n",
    "initial_states = torch.zeros(num_nodes,3) # [S,I,R]\n",
    "initial_states[:, 0] = 1\n",
    "\n",
    "graph = initial_graph\n",
    "x = []\n",
    "y = []\n",
    "for i in range(100): \n",
    "    # set infected individual\n",
    "    idx = torch.randint(0,num_nodes, (1,))\n",
    "    initial_states[idx.item(), 0] = 0\n",
    "    initial_states[idx.item(), 1] = 1\n",
    "\n",
    "    model = NetSIR(num_nodes=initial_graph.shape[0], horizon=100, infection_rate=0.01, recovery_rate=0.0384) # infection_rate, recover_rate, fixed_population\n",
    "    preds = model(initial_states, initial_graph, steps = None)\n",
    "    x.append(torch.nn.functional.one_hot(preds[-1].argmax(1)))\n",
    "    y.append(initial_states.argmax(1))\n",
    "x = torch.stack(x)\n",
    "y = torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UniversalDataset(x=x,y=y,graph=initial_graph)\n",
    "dataset.transforms = transformation\n",
    "task = Detection(prototype=GCN, dataset=dataset, lookback=lookback, horizon=horizon, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spatial model loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 110.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training loss: 0.6372864246368408\n",
      "Final Validation loss: 0.4883958101272583\n",
      "\n",
      "Predicting Progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 2215.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = task.train_model(dataset=dataset, loss='ce', epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
