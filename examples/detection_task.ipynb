{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from epilearn.models.SpatialTemporal.STGCN import STGCN\n",
    "\n",
    "from epilearn.models.Spatial.GCN import GCN\n",
    "from epilearn.models.Spatial.SAGE import SAGE\n",
    "from epilearn.models.Spatial.GAT import GAT\n",
    "from epilearn.models.Spatial.GIN import GIN\n",
    "\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import utils, transforms\n",
    "from epilearn.utils import simulation\n",
    "from epilearn.tasks.detection import Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial settings\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(7)\n",
    "\n",
    "lookback = 1 # inputs size\n",
    "horizon = 2 # predicts size; also seen as number of classes\n",
    "\n",
    "epochs = 50 # training epochs\n",
    "batch_size = 25 # training batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load toy dataset\n",
    "dataset = UniversalDataset()\n",
    "dataset.load_toy_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize model and task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Detection(prototype=GIN, dataset=None, lookback=lookback, horizon=horizon, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation = transforms.Compose({\n",
    "#                                  'features':[transforms.normalize_feat()], \n",
    "#                                  'graph': [transforms.normalize_adj()], \n",
    "#                                  'dynamic_graph': [transforms.normalize_adj()], \n",
    "#                                  'states': []\n",
    "#                                  })\n",
    "transformation = transforms.Compose({\n",
    "                                 'features':[], \n",
    "                                 'graph': [], \n",
    "                                 'dynamic_graph': [], \n",
    "                                 'states': []\n",
    "                                 })\n",
    "dataset.transforms = transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = None\n",
    "result = task.train_model(dataset=dataset, config=config, loss='ce', epochs=5) # instead of config, we can also dircetly input some parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Simulated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation Process\n",
    "from epilearn.models.SpatialTemporal.NetworkSIR import NetSIR\n",
    "\n",
    "# generate 10 samples\n",
    "num_nodes = 25\n",
    "# generate random static graph: 25 nodes\n",
    "initial_graph = simulation.get_random_graph(num_nodes=num_nodes, connect_prob=0.15)\n",
    "initial_states = torch.zeros(num_nodes,3) # [S,I,R]\n",
    "initial_states[:, 0] = 1\n",
    "\n",
    "graph = initial_graph\n",
    "x = []\n",
    "y = []\n",
    "for i in range(100): \n",
    "    # set infected individual\n",
    "    idx = torch.randint(0,num_nodes, (1,))\n",
    "    initial_states[idx.item(), 0] = 0\n",
    "    initial_states[idx.item(), 1] = 1\n",
    "\n",
    "    model = NetSIR(num_nodes=initial_graph.shape[0], horizon=100, infection_rate=0.01, recovery_rate=0.0384) # infection_rate, recover_rate, fixed_population\n",
    "    preds = model(initial_states, initial_graph, steps = None)\n",
    "    x.append(torch.nn.functional.one_hot(preds[-1].argmax(1)))\n",
    "    y.append(initial_states.argmax(1))\n",
    "x = torch.stack(x)\n",
    "y = torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = UniversalDataset(x=x,y=y,graph=initial_graph)\n",
    "dataset.transforms = transformation\n",
    "task = Detection(prototype=GCN, dataset=dataset, lookback=lookback, horizon=horizon, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = task.train_model(dataset=dataset, loss='ce', epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
