{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T07:45:41.170717900Z",
     "start_time": "2024-04-26T07:45:41.100208300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from epilearn.models.SpatialTemporal.STGCN import STGCN\n",
    "from epilearn.models.Spatial.GCN import GCN\n",
    "from epilearn.models.Spatial.GAT import GAT\n",
    "from epilearn.models.Spatial.SAGE import SAGE\n",
    "from epilearn.models.Spatial.GIN import GIN\n",
    "\n",
    "\n",
    "\n",
    "from epilearn.data import UniversalDataset\n",
    "from epilearn.utils import utils, metrics\n",
    "from epilearn.utils import transforms\n",
    "\n",
    "# initial settings\n",
    "device = torch.device('cpu')\n",
    "torch.manual_seed(7)\n",
    "\n",
    "lookback = 12 # inputs size\n",
    "horizon = 3 # predicts size\n",
    "\n",
    "# permutation is True when using STGCN\n",
    "permute = True\n",
    "\n",
    "epochs = 50 # training epochs\n",
    "batch_size = 50 # training batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load toy dataset\n",
    "dataset = UniversalDataset()\n",
    "dataset.load_toy_dataset()\n",
    "\n",
    "# initialize transforms\n",
    "transformation = transforms.Compose({\n",
    "                                        'features': [\n",
    "                                                    transforms.normalize_feat(),\n",
    "\n",
    "                                                ],\n",
    "                                        \"target\": [transforms.normalize_feat()],\n",
    "                                        'graph': [\n",
    "                                                transforms.normalize_adj(),\n",
    "                                                    \n",
    "                                            ],\n",
    "                                        'dynamic_graph': [\n",
    "                                                        transforms.normalize_adj(),\n",
    "                                                    \n",
    "                                                    ],\n",
    "                                        'states': []\n",
    "                                    })\n",
    "\n",
    "\n",
    "# preprocessing dataset\n",
    "dataset.transforms = transformation\n",
    "\n",
    "features, target, adj_norm, adj_dynamic_norm, states = dataset.get_transformed().values()\n",
    "mean, std = dataset.transforms.feat_mean, dataset.transforms.feat_std\n",
    "\n",
    "features = features.to(device)\n",
    "adj_norm = adj_norm.to(device)\n",
    "adj_dynamic_norm = adj_dynamic_norm.to(device)\n",
    "\n",
    "# split data\n",
    "train_rate = 0.6 \n",
    "val_rate = 0.2\n",
    "\n",
    "target_feat_idx = None\n",
    "target_idx = None\n",
    "\n",
    "split_line1 = int(features.shape[0] * train_rate)\n",
    "split_line2 = int(features.shape[0] * (train_rate + val_rate))\n",
    "\n",
    "train_original_input = features[:split_line1, :, :]\n",
    "val_original_input = features[split_line1:split_line2, :, :]\n",
    "test_original_input = features[split_line2:, :, :]\n",
    "\n",
    "train_original_target = target[:split_line1, :]\n",
    "val_original_target = target[split_line1:split_line2, :]\n",
    "test_original_target = target[split_line2:, :]\n",
    "\n",
    "train_original_states = dataset.states[:split_line1, :, :]\n",
    "val_original_states = dataset.states[split_line1:split_line2, :, :]\n",
    "test_original_states = dataset.states[split_line2:, :, :]\n",
    "\n",
    "\n",
    "train_input, train_target, train_states, train_adj = dataset.generate_dataset(X = train_original_input, Y = train_original_target, states = train_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute)\n",
    "val_input, val_target, val_states, val_adj = dataset.generate_dataset(X = val_original_input, Y = val_original_target, states = val_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute)\n",
    "test_input, test_target, test_states, test_adj = dataset.generate_dataset(X = test_original_input, Y = test_original_target, states = test_original_states, dynamic_adj = adj_dynamic_norm, lookback_window_size = lookback, horizon_size = horizon, permute = permute)\n",
    "\n",
    "# prepare model\n",
    "\n",
    "model = GCN(num_features=train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        num_classes=horizon,\n",
    "        nlayers=2, with_bn=True,\n",
    "        dropout=0.3, device=device)\n",
    "\n",
    "'''model = GAT(num_features=train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        num_classes=horizon,\n",
    "        nlayers=2, with_bn=True, nheads=[2,4], concat=True,\n",
    "        dropout=0.3, device=device)'''\n",
    "\n",
    "'''model = SAGE(num_features=train_input.shape[2]*train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        num_classes=horizon,\n",
    "        nlayers=1, with_bn=True, aggr=torch_geometric.nn.GRUAggregation,\n",
    "        dropout=0.3, device=device)'''\n",
    "\n",
    "'''model = GIN(num_features=train_input.shape[2]*train_input.shape[3],\n",
    "        hidden_dim=16,\n",
    "        num_classes=horizon,\n",
    "        nlayers=2, \n",
    "        dropout=0.3, device=device)'''\n",
    "\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [00:00<00:00,  4.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:0\n",
      "Training loss: 0.3872576653957367\n",
      "Validation loss: 0.9298735857009888\n",
      "######### epoch:1\n",
      "Training loss: 0.22991551458835602\n",
      "Validation loss: 0.8498268127441406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:00<00:00,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:2\n",
      "Training loss: 0.19858981668949127\n",
      "Validation loss: 0.8344860076904297\n",
      "######### epoch:3\n",
      "Training loss: 0.18580546975135803\n",
      "Validation loss: 0.8266456723213196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:01<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### epoch:4\n",
      "Training loss: 0.17548179626464844\n",
      "Validation loss: 0.8167476654052734\n",
      "\n",
      "Final Training loss: 0.17548179626464844\n",
      "Final Validation loss: 0.8167476654052734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit(\n",
    "        train_input=train_input[..., 0,:], \n",
    "        train_target=train_target, \n",
    "        train_states=None, \n",
    "        train_graph=adj_norm, \n",
    "        train_dynamic_graph=None,\n",
    "        val_input=val_input[..., 0,:], \n",
    "        val_target=val_target,\n",
    "        val_states=None, \n",
    "        val_graph=adj_norm, \n",
    "        val_dynamic_graph=None,\n",
    "        loss='mse', \n",
    "        epochs=5, \n",
    "        batch_size=10,\n",
    "        lr=1e-3, \n",
    "        weight_decay=1e-3,\n",
    "        initialize=True, \n",
    "        verbose=True, \n",
    "        patience=10, \n",
    "        shuffle=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting Progress...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 663.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 220.9887237548828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate\n",
    "out = model.predict(feature=test_input[..., 0,:], \n",
    "                    graph=adj_norm, \n",
    "                    states=None, \n",
    "                    dynamic_graph=None, \n",
    "                    batch_size=1, \n",
    "                    device = device, \n",
    "                    shuffle=False)\n",
    "\n",
    "preds = out.detach().cpu()*std[0]+mean[0]\n",
    "targets = test_target.detach().cpu()*std[0]+mean[0]\n",
    "# MAE\n",
    "mae = metrics.get_MAE(preds, targets)\n",
    "print(f\"MAE: {mae.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualization\n",
    "# out = model.predict(feature=train_input, graph=adj_norm).detach().cpu()\n",
    "\n",
    "# sample = 28\n",
    "\n",
    "# plt.figure(figsize=(15 ,5))\n",
    "# for i in range(1, 4):\n",
    "#     sample_input=train_input[sample, i, :, 0]\n",
    "#     sample_output=out[sample, i, :]\n",
    "#     sample_target=train_target[sample, i, :]\n",
    "\n",
    "#     vis_data = torch.cat([sample_input, sample_target]).numpy()\n",
    "    \n",
    "#     plt.subplot(1, 3, i)\n",
    "#     rng = list(range(lookback+horizon))\n",
    "#     plt.plot(rng, vis_data, label=\"ground truth\")\n",
    "#     plt.plot(rng[lookback:lookback+horizon], sample_output.numpy(), label=\"prediction\")\n",
    "#     plt.legend()\n",
    "\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epilearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
